// auto generated by tdr 2.7.37, don't edit!
//
//     go code compiler
//     author: cowhuang@tencent.com
//
// create time: 2022-07-30 23:05:29
package tcaplus_uecqms

import (
	"encoding/binary"
	"errors"

	"git.woa.com/tsf4g/tdrcom"
)

const (
	Tb_UserBaseVersion    uint32 = 1
	Tb_UserCurrentVersion uint32 = 1
)

var Tb_UserDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "OssUser",
	PrimaryKey:    "OssUser,AccessId",
	Index2Column: map[string]string{
		"Index_Oss": "OssUser",
	},
}

// Tb_User
type Tb_User struct {
	OssUser string `tdr_field:"ossUser"`

	AccessId string `tdr_field:"accessId"`

	AccessKey string `tdr_field:"accessKey"`
}

func NewTb_User() *Tb_User {
	obj := new(Tb_User)
	obj.Init()
	return obj
}

func (this *Tb_User) GetBaseVersion() uint32 {
	return Tb_UserBaseVersion
}

func (this *Tb_User) GetCurrentVersion() uint32 {
	return Tb_UserCurrentVersion
}

func (this *Tb_User) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_UserDBFeilds
}

func (this *Tb_User) Init() {

}

func (this *Tb_User) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_User Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_User) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_UserCurrentVersion {
		cutVer = Tb_UserCurrentVersion
	}
	// check cut version
	if cutVer < Tb_UserBaseVersion {
		return errors.New("Tb_User cut version must large than Tb_UserBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.OssUser))+1)
	if err != nil {
		return errors.New("Tb_User.OssUser string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.OssUser), 0))
	if err != nil {
		return errors.New("Tb_User.OssUser string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.AccessId))+1)
	if err != nil {
		return errors.New("Tb_User.AccessId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.AccessId), 0))
	if err != nil {
		return errors.New("Tb_User.AccessId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.AccessKey))+1)
	if err != nil {
		return errors.New("Tb_User.AccessKey string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.AccessKey), 0))
	if err != nil {
		return errors.New("Tb_User.AccessKey string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_User) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_User data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_User) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_UserCurrentVersion {
		cutVer = Tb_UserCurrentVersion
	}
	// check version
	if cutVer < Tb_UserBaseVersion {
		errors.New("Tb_User cut version must large than Tb_UserBaseVersion\n")
	}

	var ossUserSize uint32
	err = binary.Read(r, binary.BigEndian, &ossUserSize)
	if err != nil {
		return errors.New("Tb_User.OssUser string size unpack error\n" + err.Error())
	}

	ossUserBytes := make([]byte, ossUserSize)
	err = binary.Read(r, binary.BigEndian, ossUserBytes)
	if err != nil {
		return errors.New("Tb_User.OssUser string content unpack error\n" + err.Error())
	}
	this.OssUser = string(ossUserBytes[:len(ossUserBytes)-1])

	var accessIdSize uint32
	err = binary.Read(r, binary.BigEndian, &accessIdSize)
	if err != nil {
		return errors.New("Tb_User.AccessId string size unpack error\n" + err.Error())
	}

	accessIdBytes := make([]byte, accessIdSize)
	err = binary.Read(r, binary.BigEndian, accessIdBytes)
	if err != nil {
		return errors.New("Tb_User.AccessId string content unpack error\n" + err.Error())
	}
	this.AccessId = string(accessIdBytes[:len(accessIdBytes)-1])

	var accessKeySize uint32
	err = binary.Read(r, binary.BigEndian, &accessKeySize)
	if err != nil {
		return errors.New("Tb_User.AccessKey string size unpack error\n" + err.Error())
	}

	accessKeyBytes := make([]byte, accessKeySize)
	err = binary.Read(r, binary.BigEndian, accessKeyBytes)
	if err != nil {
		return errors.New("Tb_User.AccessKey string content unpack error\n" + err.Error())
	}
	this.AccessKey = string(accessKeyBytes[:len(accessKeyBytes)-1])

	return err
}

const (
	Tb_BucketBaseVersion    uint32 = 1
	Tb_BucketCurrentVersion uint32 = 1
)

var Tb_BucketDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "ProjectName",
	PrimaryKey:    "ProjectName,OwnerId,Name",
	Index2Column: map[string]string{
		"Index_Pno": "ProjectName,OwnerId",
	},
}

// Tb_Bucket
type Tb_Bucket struct {
	ProjectName string `tdr_field:"projectName"`

	OwnerId string `tdr_field:"ownerId"`

	Name string `tdr_field:"name"`

	BucketId string `tdr_field:"bucketId"`

	UploadTime uint64 `tdr_field:"uploadTime"`

	ObjCount uint64 `tdr_field:"objCount"`

	Size uint64 `tdr_field:"size"`

	ValidSize uint64 `tdr_field:"validSize"`

	BlockPath string `tdr_field:"blockPath"`

	BlockRemain uint64 `tdr_field:"blockRemain"`
}

func NewTb_Bucket() *Tb_Bucket {
	obj := new(Tb_Bucket)
	obj.Init()
	return obj
}

func (this *Tb_Bucket) GetBaseVersion() uint32 {
	return Tb_BucketBaseVersion
}

func (this *Tb_Bucket) GetCurrentVersion() uint32 {
	return Tb_BucketCurrentVersion
}

func (this *Tb_Bucket) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_BucketDBFeilds
}

func (this *Tb_Bucket) Init() {

}

func (this *Tb_Bucket) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Bucket Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Bucket) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_BucketCurrentVersion {
		cutVer = Tb_BucketCurrentVersion
	}
	// check cut version
	if cutVer < Tb_BucketBaseVersion {
		return errors.New("Tb_Bucket cut version must large than Tb_BucketBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ProjectName))+1)
	if err != nil {
		return errors.New("Tb_Bucket.ProjectName string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ProjectName), 0))
	if err != nil {
		return errors.New("Tb_Bucket.ProjectName string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.OwnerId))+1)
	if err != nil {
		return errors.New("Tb_Bucket.OwnerId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.OwnerId), 0))
	if err != nil {
		return errors.New("Tb_Bucket.OwnerId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Name))+1)
	if err != nil {
		return errors.New("Tb_Bucket.Name string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Name), 0))
	if err != nil {
		return errors.New("Tb_Bucket.Name string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BucketId))+1)
	if err != nil {
		return errors.New("Tb_Bucket.BucketId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BucketId), 0))
	if err != nil {
		return errors.New("Tb_Bucket.BucketId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.UploadTime)
	if err != nil {
		return errors.New("Tb_Bucket.UploadTime pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.ObjCount)
	if err != nil {
		return errors.New("Tb_Bucket.ObjCount pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Size)
	if err != nil {
		return errors.New("Tb_Bucket.Size pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.ValidSize)
	if err != nil {
		return errors.New("Tb_Bucket.ValidSize pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Bucket.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Bucket.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.BlockRemain)
	if err != nil {
		return errors.New("Tb_Bucket.BlockRemain pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Bucket) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Bucket data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Bucket) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_BucketCurrentVersion {
		cutVer = Tb_BucketCurrentVersion
	}
	// check version
	if cutVer < Tb_BucketBaseVersion {
		errors.New("Tb_Bucket cut version must large than Tb_BucketBaseVersion\n")
	}

	var projectNameSize uint32
	err = binary.Read(r, binary.BigEndian, &projectNameSize)
	if err != nil {
		return errors.New("Tb_Bucket.ProjectName string size unpack error\n" + err.Error())
	}

	projectNameBytes := make([]byte, projectNameSize)
	err = binary.Read(r, binary.BigEndian, projectNameBytes)
	if err != nil {
		return errors.New("Tb_Bucket.ProjectName string content unpack error\n" + err.Error())
	}
	this.ProjectName = string(projectNameBytes[:len(projectNameBytes)-1])

	var ownerIdSize uint32
	err = binary.Read(r, binary.BigEndian, &ownerIdSize)
	if err != nil {
		return errors.New("Tb_Bucket.OwnerId string size unpack error\n" + err.Error())
	}

	ownerIdBytes := make([]byte, ownerIdSize)
	err = binary.Read(r, binary.BigEndian, ownerIdBytes)
	if err != nil {
		return errors.New("Tb_Bucket.OwnerId string content unpack error\n" + err.Error())
	}
	this.OwnerId = string(ownerIdBytes[:len(ownerIdBytes)-1])

	var nameSize uint32
	err = binary.Read(r, binary.BigEndian, &nameSize)
	if err != nil {
		return errors.New("Tb_Bucket.Name string size unpack error\n" + err.Error())
	}

	nameBytes := make([]byte, nameSize)
	err = binary.Read(r, binary.BigEndian, nameBytes)
	if err != nil {
		return errors.New("Tb_Bucket.Name string content unpack error\n" + err.Error())
	}
	this.Name = string(nameBytes[:len(nameBytes)-1])

	var bucketIdSize uint32
	err = binary.Read(r, binary.BigEndian, &bucketIdSize)
	if err != nil {
		return errors.New("Tb_Bucket.BucketId string size unpack error\n" + err.Error())
	}

	bucketIdBytes := make([]byte, bucketIdSize)
	err = binary.Read(r, binary.BigEndian, bucketIdBytes)
	if err != nil {
		return errors.New("Tb_Bucket.BucketId string content unpack error\n" + err.Error())
	}
	this.BucketId = string(bucketIdBytes[:len(bucketIdBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.UploadTime)
	if err != nil {
		return errors.New("Tb_Bucket.UploadTime unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.ObjCount)
	if err != nil {
		return errors.New("Tb_Bucket.ObjCount unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Size)
	if err != nil {
		return errors.New("Tb_Bucket.Size unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.ValidSize)
	if err != nil {
		return errors.New("Tb_Bucket.ValidSize unpack error\n" + err.Error())
	}

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Bucket.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Bucket.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.BlockRemain)
	if err != nil {
		return errors.New("Tb_Bucket.BlockRemain unpack error\n" + err.Error())
	}

	return err
}

const (
	Tb_Object_SliceBaseVersion    uint32 = 1
	Tb_Object_SliceCurrentVersion uint32 = 1
)

// Tb_Object_Slice
type Tb_Object_Slice struct {
	ObjectId string `tdr_field:"objectId"`

	SliceId uint32 `tdr_field:"sliceId"`

	NodeId uint64 `tdr_field:"nodeId"`

	Type uint32 `tdr_field:"type"`

	BlockPath string `tdr_field:"blockPath"`

	Offset uint64 `tdr_field:"offset"`

	Length uint64 `tdr_field:"length"`

	Md5 string `tdr_field:"md5"`
}

func NewTb_Object_Slice() *Tb_Object_Slice {
	obj := new(Tb_Object_Slice)
	obj.Init()
	return obj
}

func (this *Tb_Object_Slice) GetBaseVersion() uint32 {
	return Tb_Object_SliceBaseVersion
}

func (this *Tb_Object_Slice) GetCurrentVersion() uint32 {
	return Tb_Object_SliceCurrentVersion
}

func (this *Tb_Object_Slice) Init() {

}

func (this *Tb_Object_Slice) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Object_Slice Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Object_Slice) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Object_SliceCurrentVersion {
		cutVer = Tb_Object_SliceCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Object_SliceBaseVersion {
		return errors.New("Tb_Object_Slice cut version must large than Tb_Object_SliceBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ObjectId))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice.ObjectId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ObjectId), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice.ObjectId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceId)
	if err != nil {
		return errors.New("Tb_Object_Slice.SliceId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.NodeId)
	if err != nil {
		return errors.New("Tb_Object_Slice.NodeId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Type)
	if err != nil {
		return errors.New("Tb_Object_Slice.Type pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Offset)
	if err != nil {
		return errors.New("Tb_Object_Slice.Offset pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Length)
	if err != nil {
		return errors.New("Tb_Object_Slice.Length pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Md5))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice.Md5 string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Md5), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice.Md5 string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Object_Slice) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Object_Slice data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Object_Slice) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Object_SliceCurrentVersion {
		cutVer = Tb_Object_SliceCurrentVersion
	}
	// check version
	if cutVer < Tb_Object_SliceBaseVersion {
		errors.New("Tb_Object_Slice cut version must large than Tb_Object_SliceBaseVersion\n")
	}

	var objectIdSize uint32
	err = binary.Read(r, binary.BigEndian, &objectIdSize)
	if err != nil {
		return errors.New("Tb_Object_Slice.ObjectId string size unpack error\n" + err.Error())
	}

	objectIdBytes := make([]byte, objectIdSize)
	err = binary.Read(r, binary.BigEndian, objectIdBytes)
	if err != nil {
		return errors.New("Tb_Object_Slice.ObjectId string content unpack error\n" + err.Error())
	}
	this.ObjectId = string(objectIdBytes[:len(objectIdBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.SliceId)
	if err != nil {
		return errors.New("Tb_Object_Slice.SliceId unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.NodeId)
	if err != nil {
		return errors.New("Tb_Object_Slice.NodeId unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Type)
	if err != nil {
		return errors.New("Tb_Object_Slice.Type unpack error\n" + err.Error())
	}

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Object_Slice.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Object_Slice.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.Offset)
	if err != nil {
		return errors.New("Tb_Object_Slice.Offset unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Length)
	if err != nil {
		return errors.New("Tb_Object_Slice.Length unpack error\n" + err.Error())
	}

	var md5Size uint32
	err = binary.Read(r, binary.BigEndian, &md5Size)
	if err != nil {
		return errors.New("Tb_Object_Slice.Md5 string size unpack error\n" + err.Error())
	}

	md5Bytes := make([]byte, md5Size)
	err = binary.Read(r, binary.BigEndian, md5Bytes)
	if err != nil {
		return errors.New("Tb_Object_Slice.Md5 string content unpack error\n" + err.Error())
	}
	this.Md5 = string(md5Bytes[:len(md5Bytes)-1])

	return err
}

const (
	Tb_Object_MetadataBaseVersion    uint32 = 1
	Tb_Object_MetadataCurrentVersion uint32 = 1
)

var Tb_Object_MetadataDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "BucketId",
	PrimaryKey:    "BucketId,ObjectId",
	Index2Column: map[string]string{
		"Index_B": "BucketId",
	},
}

// Tb_Object_Metadata
type Tb_Object_Metadata struct {
	BucketId string `tdr_field:"bucketId"`

	ObjectName string `tdr_field:"objectName"`

	ObjectId string `tdr_field:"objectId"`

	ContentLength uint64 `tdr_field:"contentLength"`

	ContentType string `tdr_field:"contentType"`

	ContentEncode string `tdr_field:"contentEncode"`

	Suffix string `tdr_field:"suffix"`

	UploadTime uint64 `tdr_field:"uploadTime"`

	Md5 string `tdr_field:"md5"`

	IsEncript uint32 `tdr_field:"isEncript"`

	EncriptAlgo string `tdr_field:"encriptAlgo"`

	SliceDataCount uint32 `tdr_field:"sliceDataCount"`

	SliceECCodeCount uint32 `tdr_field:"sliceECCodeCount"`

	Expire uint64 `tdr_field:"expire"`

	SliceCount int32 `tdr_field:"sliceCount"`

	SliceInfo []*Tb_Object_Slice `tdr_field:"sliceInfo" tdr_count:"10" tdr_refer:"SliceCount"`
}

func NewTb_Object_Metadata() *Tb_Object_Metadata {
	obj := new(Tb_Object_Metadata)
	obj.Init()
	return obj
}

func (this *Tb_Object_Metadata) GetBaseVersion() uint32 {
	return Tb_Object_MetadataBaseVersion
}

func (this *Tb_Object_Metadata) GetCurrentVersion() uint32 {
	return Tb_Object_MetadataCurrentVersion
}

func (this *Tb_Object_Metadata) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Object_MetadataDBFeilds
}

func (this *Tb_Object_Metadata) Init() {

}

func (this *Tb_Object_Metadata) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Object_Metadata Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Object_Metadata) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Object_MetadataCurrentVersion {
		cutVer = Tb_Object_MetadataCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Object_MetadataBaseVersion {
		return errors.New("Tb_Object_Metadata cut version must large than Tb_Object_MetadataBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BucketId))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.BucketId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BucketId), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.BucketId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ObjectName))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectName string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ObjectName), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectName string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ObjectId))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ObjectId), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.ContentLength)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentLength pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ContentType))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentType string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ContentType), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentType string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ContentEncode))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentEncode string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ContentEncode), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentEncode string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Suffix))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Suffix string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Suffix), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.Suffix string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.UploadTime)
	if err != nil {
		return errors.New("Tb_Object_Metadata.UploadTime pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Md5))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Md5 string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Md5), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.Md5 string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.IsEncript)
	if err != nil {
		return errors.New("Tb_Object_Metadata.IsEncript pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.EncriptAlgo))+1)
	if err != nil {
		return errors.New("Tb_Object_Metadata.EncriptAlgo string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.EncriptAlgo), 0))
	if err != nil {
		return errors.New("Tb_Object_Metadata.EncriptAlgo string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceDataCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceDataCount pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceECCodeCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceECCodeCount pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Expire)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Expire pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceCount pack error\n" + err.Error())
	}

	if this.SliceCount < 0 {
		return errors.New("Tb_Object_Metadata.SliceInfo's refer SliceCount should >= 0")
	}
	if this.SliceCount > 10 {
		return errors.New("Tb_Object_Metadata.SliceInfo's refer SliceCount should <= count 10")
	}
	if len(this.SliceInfo) < int(this.SliceCount) {
		return errors.New("Tb_Object_Metadata.SliceInfo's length should > SliceCount")
	}
	if this.SliceCount > 0 {
		for i := 0; i < int(this.SliceCount); i++ {
			err = this.SliceInfo[i].PackTo(cutVer, w)
			if err != nil {
				return errors.New("Tb_Object_Metadata.SliceInfo pack error\n" + err.Error())
			}

		}
	}

	return nil
}

func (this *Tb_Object_Metadata) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Object_Metadata data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Object_Metadata) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Object_MetadataCurrentVersion {
		cutVer = Tb_Object_MetadataCurrentVersion
	}
	// check version
	if cutVer < Tb_Object_MetadataBaseVersion {
		errors.New("Tb_Object_Metadata cut version must large than Tb_Object_MetadataBaseVersion\n")
	}

	var bucketIdSize uint32
	err = binary.Read(r, binary.BigEndian, &bucketIdSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.BucketId string size unpack error\n" + err.Error())
	}

	bucketIdBytes := make([]byte, bucketIdSize)
	err = binary.Read(r, binary.BigEndian, bucketIdBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.BucketId string content unpack error\n" + err.Error())
	}
	this.BucketId = string(bucketIdBytes[:len(bucketIdBytes)-1])

	var objectNameSize uint32
	err = binary.Read(r, binary.BigEndian, &objectNameSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectName string size unpack error\n" + err.Error())
	}

	objectNameBytes := make([]byte, objectNameSize)
	err = binary.Read(r, binary.BigEndian, objectNameBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectName string content unpack error\n" + err.Error())
	}
	this.ObjectName = string(objectNameBytes[:len(objectNameBytes)-1])

	var objectIdSize uint32
	err = binary.Read(r, binary.BigEndian, &objectIdSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectId string size unpack error\n" + err.Error())
	}

	objectIdBytes := make([]byte, objectIdSize)
	err = binary.Read(r, binary.BigEndian, objectIdBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ObjectId string content unpack error\n" + err.Error())
	}
	this.ObjectId = string(objectIdBytes[:len(objectIdBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.ContentLength)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentLength unpack error\n" + err.Error())
	}

	var contentTypeSize uint32
	err = binary.Read(r, binary.BigEndian, &contentTypeSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentType string size unpack error\n" + err.Error())
	}

	contentTypeBytes := make([]byte, contentTypeSize)
	err = binary.Read(r, binary.BigEndian, contentTypeBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentType string content unpack error\n" + err.Error())
	}
	this.ContentType = string(contentTypeBytes[:len(contentTypeBytes)-1])

	var contentEncodeSize uint32
	err = binary.Read(r, binary.BigEndian, &contentEncodeSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentEncode string size unpack error\n" + err.Error())
	}

	contentEncodeBytes := make([]byte, contentEncodeSize)
	err = binary.Read(r, binary.BigEndian, contentEncodeBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.ContentEncode string content unpack error\n" + err.Error())
	}
	this.ContentEncode = string(contentEncodeBytes[:len(contentEncodeBytes)-1])

	var suffixSize uint32
	err = binary.Read(r, binary.BigEndian, &suffixSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Suffix string size unpack error\n" + err.Error())
	}

	suffixBytes := make([]byte, suffixSize)
	err = binary.Read(r, binary.BigEndian, suffixBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Suffix string content unpack error\n" + err.Error())
	}
	this.Suffix = string(suffixBytes[:len(suffixBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.UploadTime)
	if err != nil {
		return errors.New("Tb_Object_Metadata.UploadTime unpack error\n" + err.Error())
	}

	var md5Size uint32
	err = binary.Read(r, binary.BigEndian, &md5Size)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Md5 string size unpack error\n" + err.Error())
	}

	md5Bytes := make([]byte, md5Size)
	err = binary.Read(r, binary.BigEndian, md5Bytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Md5 string content unpack error\n" + err.Error())
	}
	this.Md5 = string(md5Bytes[:len(md5Bytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.IsEncript)
	if err != nil {
		return errors.New("Tb_Object_Metadata.IsEncript unpack error\n" + err.Error())
	}

	var encriptAlgoSize uint32
	err = binary.Read(r, binary.BigEndian, &encriptAlgoSize)
	if err != nil {
		return errors.New("Tb_Object_Metadata.EncriptAlgo string size unpack error\n" + err.Error())
	}

	encriptAlgoBytes := make([]byte, encriptAlgoSize)
	err = binary.Read(r, binary.BigEndian, encriptAlgoBytes)
	if err != nil {
		return errors.New("Tb_Object_Metadata.EncriptAlgo string content unpack error\n" + err.Error())
	}
	this.EncriptAlgo = string(encriptAlgoBytes[:len(encriptAlgoBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.SliceDataCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceDataCount unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.SliceECCodeCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceECCodeCount unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Expire)
	if err != nil {
		return errors.New("Tb_Object_Metadata.Expire unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.SliceCount)
	if err != nil {
		return errors.New("Tb_Object_Metadata.SliceCount unpack error\n" + err.Error())
	}

	if this.SliceCount < 0 {
		return errors.New("Tb_Object_Metadata.SliceInfo's refer SliceCount should >= 0")
	}
	if this.SliceCount > 10 {
		return errors.New("Tb_Object_Metadata.SliceInfo's refer SliceCount should <= count 10")
	}

	if this.SliceInfo == nil {
		this.SliceInfo = make([]*Tb_Object_Slice, int(this.SliceCount))
		for i := 0; i < int(this.SliceCount); i++ {
			this.SliceInfo[i] = NewTb_Object_Slice()
		}
	}

	for i := 0; i < int(this.SliceCount); i++ {
		err = this.SliceInfo[i].UnpackFrom(cutVer, r)
		if err != nil {
			return errors.New("Tb_Object_Metadata.SliceInfo unpack error\n" + err.Error())
		}

	}

	return err
}

const (
	Tb_SliceBaseVersion    uint32 = 1
	Tb_SliceCurrentVersion uint32 = 1
)

var Tb_SliceDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "ObjectId",
	PrimaryKey:    "ObjectId,SliceId",
	Index2Column: map[string]string{
		"Index_Obj": "ObjectId",
	},
}

// Tb_Slice
type Tb_Slice struct {
	ObjectId string `tdr_field:"objectId"`

	SliceId uint32 `tdr_field:"sliceId"`

	NodeId uint64 `tdr_field:"nodeId"`

	Type uint32 `tdr_field:"type"`

	BlockPath string `tdr_field:"blockPath"`

	Offset uint64 `tdr_field:"offset"`

	Length uint64 `tdr_field:"length"`

	Md5 string `tdr_field:"md5"`
}

func NewTb_Slice() *Tb_Slice {
	obj := new(Tb_Slice)
	obj.Init()
	return obj
}

func (this *Tb_Slice) GetBaseVersion() uint32 {
	return Tb_SliceBaseVersion
}

func (this *Tb_Slice) GetCurrentVersion() uint32 {
	return Tb_SliceCurrentVersion
}

func (this *Tb_Slice) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_SliceDBFeilds
}

func (this *Tb_Slice) Init() {

}

func (this *Tb_Slice) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Slice Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Slice) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_SliceCurrentVersion {
		cutVer = Tb_SliceCurrentVersion
	}
	// check cut version
	if cutVer < Tb_SliceBaseVersion {
		return errors.New("Tb_Slice cut version must large than Tb_SliceBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ObjectId))+1)
	if err != nil {
		return errors.New("Tb_Slice.ObjectId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ObjectId), 0))
	if err != nil {
		return errors.New("Tb_Slice.ObjectId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceId)
	if err != nil {
		return errors.New("Tb_Slice.SliceId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.NodeId)
	if err != nil {
		return errors.New("Tb_Slice.NodeId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Type)
	if err != nil {
		return errors.New("Tb_Slice.Type pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Slice.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Slice.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Offset)
	if err != nil {
		return errors.New("Tb_Slice.Offset pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Length)
	if err != nil {
		return errors.New("Tb_Slice.Length pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Md5))+1)
	if err != nil {
		return errors.New("Tb_Slice.Md5 string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Md5), 0))
	if err != nil {
		return errors.New("Tb_Slice.Md5 string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Slice) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Slice data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Slice) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_SliceCurrentVersion {
		cutVer = Tb_SliceCurrentVersion
	}
	// check version
	if cutVer < Tb_SliceBaseVersion {
		errors.New("Tb_Slice cut version must large than Tb_SliceBaseVersion\n")
	}

	var objectIdSize uint32
	err = binary.Read(r, binary.BigEndian, &objectIdSize)
	if err != nil {
		return errors.New("Tb_Slice.ObjectId string size unpack error\n" + err.Error())
	}

	objectIdBytes := make([]byte, objectIdSize)
	err = binary.Read(r, binary.BigEndian, objectIdBytes)
	if err != nil {
		return errors.New("Tb_Slice.ObjectId string content unpack error\n" + err.Error())
	}
	this.ObjectId = string(objectIdBytes[:len(objectIdBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.SliceId)
	if err != nil {
		return errors.New("Tb_Slice.SliceId unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.NodeId)
	if err != nil {
		return errors.New("Tb_Slice.NodeId unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Type)
	if err != nil {
		return errors.New("Tb_Slice.Type unpack error\n" + err.Error())
	}

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Slice.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Slice.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.Offset)
	if err != nil {
		return errors.New("Tb_Slice.Offset unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Length)
	if err != nil {
		return errors.New("Tb_Slice.Length unpack error\n" + err.Error())
	}

	var md5Size uint32
	err = binary.Read(r, binary.BigEndian, &md5Size)
	if err != nil {
		return errors.New("Tb_Slice.Md5 string size unpack error\n" + err.Error())
	}

	md5Bytes := make([]byte, md5Size)
	err = binary.Read(r, binary.BigEndian, md5Bytes)
	if err != nil {
		return errors.New("Tb_Slice.Md5 string content unpack error\n" + err.Error())
	}
	this.Md5 = string(md5Bytes[:len(md5Bytes)-1])

	return err
}

const (
	Tb_Node_InfoBaseVersion    uint32 = 1
	Tb_Node_InfoCurrentVersion uint32 = 1
)

var Tb_Node_InfoDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "Node",
	PrimaryKey:    "Node,Id",
	Index2Column: map[string]string{
		"Index_N":   "Node",
		"Index_Nid": "Node,Id",
	},
}

// Tb_Node_Info
type Tb_Node_Info struct {
	Node string `tdr_field:"node"`

	Id uint64 `tdr_field:"id"`

	Ip string `tdr_field:"ip"`

	Port uint32 `tdr_field:"port"`

	Root string `tdr_field:"root"`

	BlockPath string `tdr_field:"blockPath"`

	BlockValidSpace uint64 `tdr_field:"blockValidSpace"`

	BlockSize uint64 `tdr_field:"blockSize"`

	Space uint64 `tdr_field:"space"`

	ValidSpace uint64 `tdr_field:"validSpace"`

	State byte `tdr_field:"state"`
}

func NewTb_Node_Info() *Tb_Node_Info {
	obj := new(Tb_Node_Info)
	obj.Init()
	return obj
}

func (this *Tb_Node_Info) GetBaseVersion() uint32 {
	return Tb_Node_InfoBaseVersion
}

func (this *Tb_Node_Info) GetCurrentVersion() uint32 {
	return Tb_Node_InfoCurrentVersion
}

func (this *Tb_Node_Info) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Node_InfoDBFeilds
}

func (this *Tb_Node_Info) Init() {

}

func (this *Tb_Node_Info) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Node_Info Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Node_Info) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Node_InfoCurrentVersion {
		cutVer = Tb_Node_InfoCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Node_InfoBaseVersion {
		return errors.New("Tb_Node_Info cut version must large than Tb_Node_InfoBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Node))+1)
	if err != nil {
		return errors.New("Tb_Node_Info.Node string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Node), 0))
	if err != nil {
		return errors.New("Tb_Node_Info.Node string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Id)
	if err != nil {
		return errors.New("Tb_Node_Info.Id pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Ip))+1)
	if err != nil {
		return errors.New("Tb_Node_Info.Ip string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Ip), 0))
	if err != nil {
		return errors.New("Tb_Node_Info.Ip string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Port)
	if err != nil {
		return errors.New("Tb_Node_Info.Port pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Root))+1)
	if err != nil {
		return errors.New("Tb_Node_Info.Root string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Root), 0))
	if err != nil {
		return errors.New("Tb_Node_Info.Root string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Node_Info.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.BlockValidSpace)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockValidSpace pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.BlockSize)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockSize pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Space)
	if err != nil {
		return errors.New("Tb_Node_Info.Space pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.ValidSpace)
	if err != nil {
		return errors.New("Tb_Node_Info.ValidSpace pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.State)
	if err != nil {
		return errors.New("Tb_Node_Info.State pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Node_Info) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Node_Info data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Node_Info) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Node_InfoCurrentVersion {
		cutVer = Tb_Node_InfoCurrentVersion
	}
	// check version
	if cutVer < Tb_Node_InfoBaseVersion {
		errors.New("Tb_Node_Info cut version must large than Tb_Node_InfoBaseVersion\n")
	}

	var nodeSize uint32
	err = binary.Read(r, binary.BigEndian, &nodeSize)
	if err != nil {
		return errors.New("Tb_Node_Info.Node string size unpack error\n" + err.Error())
	}

	nodeBytes := make([]byte, nodeSize)
	err = binary.Read(r, binary.BigEndian, nodeBytes)
	if err != nil {
		return errors.New("Tb_Node_Info.Node string content unpack error\n" + err.Error())
	}
	this.Node = string(nodeBytes[:len(nodeBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.Id)
	if err != nil {
		return errors.New("Tb_Node_Info.Id unpack error\n" + err.Error())
	}

	var ipSize uint32
	err = binary.Read(r, binary.BigEndian, &ipSize)
	if err != nil {
		return errors.New("Tb_Node_Info.Ip string size unpack error\n" + err.Error())
	}

	ipBytes := make([]byte, ipSize)
	err = binary.Read(r, binary.BigEndian, ipBytes)
	if err != nil {
		return errors.New("Tb_Node_Info.Ip string content unpack error\n" + err.Error())
	}
	this.Ip = string(ipBytes[:len(ipBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.Port)
	if err != nil {
		return errors.New("Tb_Node_Info.Port unpack error\n" + err.Error())
	}

	var rootSize uint32
	err = binary.Read(r, binary.BigEndian, &rootSize)
	if err != nil {
		return errors.New("Tb_Node_Info.Root string size unpack error\n" + err.Error())
	}

	rootBytes := make([]byte, rootSize)
	err = binary.Read(r, binary.BigEndian, rootBytes)
	if err != nil {
		return errors.New("Tb_Node_Info.Root string content unpack error\n" + err.Error())
	}
	this.Root = string(rootBytes[:len(rootBytes)-1])

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.BlockValidSpace)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockValidSpace unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.BlockSize)
	if err != nil {
		return errors.New("Tb_Node_Info.BlockSize unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Space)
	if err != nil {
		return errors.New("Tb_Node_Info.Space unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.ValidSpace)
	if err != nil {
		return errors.New("Tb_Node_Info.ValidSpace unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.State)
	if err != nil {
		return errors.New("Tb_Node_Info.State unpack error\n" + err.Error())
	}

	return err
}

const (
	Tb_Bucket_In_NodeBaseVersion    uint32 = 1
	Tb_Bucket_In_NodeCurrentVersion uint32 = 1
)

var Tb_Bucket_In_NodeDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "NodeId",
	PrimaryKey:    "NodeId,BucketId",
	Index2Column: map[string]string{
		"Index_N": "NodeId",
	},
}

// Tb_Bucket_In_Node
type Tb_Bucket_In_Node struct {
	NodeId uint64 `tdr_field:"nodeId"`

	BucketId string `tdr_field:"bucketId"`

	BlockPath string `tdr_field:"blockPath"`

	BlockValidSpace uint64 `tdr_field:"blockValidSpace"`
}

func NewTb_Bucket_In_Node() *Tb_Bucket_In_Node {
	obj := new(Tb_Bucket_In_Node)
	obj.Init()
	return obj
}

func (this *Tb_Bucket_In_Node) GetBaseVersion() uint32 {
	return Tb_Bucket_In_NodeBaseVersion
}

func (this *Tb_Bucket_In_Node) GetCurrentVersion() uint32 {
	return Tb_Bucket_In_NodeCurrentVersion
}

func (this *Tb_Bucket_In_Node) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Bucket_In_NodeDBFeilds
}

func (this *Tb_Bucket_In_Node) Init() {

}

func (this *Tb_Bucket_In_Node) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Bucket_In_Node Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Bucket_In_Node) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Bucket_In_NodeCurrentVersion {
		cutVer = Tb_Bucket_In_NodeCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Bucket_In_NodeBaseVersion {
		return errors.New("Tb_Bucket_In_Node cut version must large than Tb_Bucket_In_NodeBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, this.NodeId)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.NodeId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BucketId))+1)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BucketId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BucketId), 0))
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BucketId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.BlockValidSpace)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockValidSpace pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Bucket_In_Node) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Bucket_In_Node data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Bucket_In_Node) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Bucket_In_NodeCurrentVersion {
		cutVer = Tb_Bucket_In_NodeCurrentVersion
	}
	// check version
	if cutVer < Tb_Bucket_In_NodeBaseVersion {
		errors.New("Tb_Bucket_In_Node cut version must large than Tb_Bucket_In_NodeBaseVersion\n")
	}

	err = binary.Read(r, binary.BigEndian, &this.NodeId)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.NodeId unpack error\n" + err.Error())
	}

	var bucketIdSize uint32
	err = binary.Read(r, binary.BigEndian, &bucketIdSize)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BucketId string size unpack error\n" + err.Error())
	}

	bucketIdBytes := make([]byte, bucketIdSize)
	err = binary.Read(r, binary.BigEndian, bucketIdBytes)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BucketId string content unpack error\n" + err.Error())
	}
	this.BucketId = string(bucketIdBytes[:len(bucketIdBytes)-1])

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.BlockValidSpace)
	if err != nil {
		return errors.New("Tb_Bucket_In_Node.BlockValidSpace unpack error\n" + err.Error())
	}

	return err
}

const (
	Tb_Metadata_Need_DeleteBaseVersion    uint32 = 1
	Tb_Metadata_Need_DeleteCurrentVersion uint32 = 1
)

var Tb_Metadata_Need_DeleteDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "Flag",
	PrimaryKey:    "Flag,BucketId",
	Index2Column: map[string]string{
		"Index_F": "Flag",
	},
}

// Tb_Metadata_Need_Delete
type Tb_Metadata_Need_Delete struct {
	Flag string `tdr_field:"flag"`

	BucketId string `tdr_field:"bucketId"`
}

func NewTb_Metadata_Need_Delete() *Tb_Metadata_Need_Delete {
	obj := new(Tb_Metadata_Need_Delete)
	obj.Init()
	return obj
}

func (this *Tb_Metadata_Need_Delete) GetBaseVersion() uint32 {
	return Tb_Metadata_Need_DeleteBaseVersion
}

func (this *Tb_Metadata_Need_Delete) GetCurrentVersion() uint32 {
	return Tb_Metadata_Need_DeleteCurrentVersion
}

func (this *Tb_Metadata_Need_Delete) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Metadata_Need_DeleteDBFeilds
}

func (this *Tb_Metadata_Need_Delete) Init() {

}

func (this *Tb_Metadata_Need_Delete) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Metadata_Need_Delete Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Metadata_Need_Delete) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Metadata_Need_DeleteCurrentVersion {
		cutVer = Tb_Metadata_Need_DeleteCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Metadata_Need_DeleteBaseVersion {
		return errors.New("Tb_Metadata_Need_Delete cut version must large than Tb_Metadata_Need_DeleteBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Flag))+1)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.Flag string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Flag), 0))
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.Flag string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BucketId))+1)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.BucketId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BucketId), 0))
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.BucketId string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Metadata_Need_Delete) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Metadata_Need_Delete data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Metadata_Need_Delete) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Metadata_Need_DeleteCurrentVersion {
		cutVer = Tb_Metadata_Need_DeleteCurrentVersion
	}
	// check version
	if cutVer < Tb_Metadata_Need_DeleteBaseVersion {
		errors.New("Tb_Metadata_Need_Delete cut version must large than Tb_Metadata_Need_DeleteBaseVersion\n")
	}

	var flagSize uint32
	err = binary.Read(r, binary.BigEndian, &flagSize)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.Flag string size unpack error\n" + err.Error())
	}

	flagBytes := make([]byte, flagSize)
	err = binary.Read(r, binary.BigEndian, flagBytes)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.Flag string content unpack error\n" + err.Error())
	}
	this.Flag = string(flagBytes[:len(flagBytes)-1])

	var bucketIdSize uint32
	err = binary.Read(r, binary.BigEndian, &bucketIdSize)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.BucketId string size unpack error\n" + err.Error())
	}

	bucketIdBytes := make([]byte, bucketIdSize)
	err = binary.Read(r, binary.BigEndian, bucketIdBytes)
	if err != nil {
		return errors.New("Tb_Metadata_Need_Delete.BucketId string content unpack error\n" + err.Error())
	}
	this.BucketId = string(bucketIdBytes[:len(bucketIdBytes)-1])

	return err
}

const (
	Tb_Bucket_Need_DeleteBaseVersion    uint32 = 1
	Tb_Bucket_Need_DeleteCurrentVersion uint32 = 1
)

var Tb_Bucket_Need_DeleteDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "Flag",
	PrimaryKey:    "Flag,NodeId,BucketId",
	Index2Column: map[string]string{
		"Index_F": "Flag",
	},
}

// Tb_Bucket_Need_Delete
type Tb_Bucket_Need_Delete struct {
	Flag string `tdr_field:"flag"`

	NodeId uint64 `tdr_field:"nodeId"`

	BucketId string `tdr_field:"bucketId"`
}

func NewTb_Bucket_Need_Delete() *Tb_Bucket_Need_Delete {
	obj := new(Tb_Bucket_Need_Delete)
	obj.Init()
	return obj
}

func (this *Tb_Bucket_Need_Delete) GetBaseVersion() uint32 {
	return Tb_Bucket_Need_DeleteBaseVersion
}

func (this *Tb_Bucket_Need_Delete) GetCurrentVersion() uint32 {
	return Tb_Bucket_Need_DeleteCurrentVersion
}

func (this *Tb_Bucket_Need_Delete) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Bucket_Need_DeleteDBFeilds
}

func (this *Tb_Bucket_Need_Delete) Init() {

}

func (this *Tb_Bucket_Need_Delete) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Bucket_Need_Delete Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Bucket_Need_Delete) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Bucket_Need_DeleteCurrentVersion {
		cutVer = Tb_Bucket_Need_DeleteCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Bucket_Need_DeleteBaseVersion {
		return errors.New("Tb_Bucket_Need_Delete cut version must large than Tb_Bucket_Need_DeleteBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Flag))+1)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.Flag string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Flag), 0))
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.Flag string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.NodeId)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.NodeId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BucketId))+1)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.BucketId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BucketId), 0))
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.BucketId string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Bucket_Need_Delete) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Bucket_Need_Delete data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Bucket_Need_Delete) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Bucket_Need_DeleteCurrentVersion {
		cutVer = Tb_Bucket_Need_DeleteCurrentVersion
	}
	// check version
	if cutVer < Tb_Bucket_Need_DeleteBaseVersion {
		errors.New("Tb_Bucket_Need_Delete cut version must large than Tb_Bucket_Need_DeleteBaseVersion\n")
	}

	var flagSize uint32
	err = binary.Read(r, binary.BigEndian, &flagSize)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.Flag string size unpack error\n" + err.Error())
	}

	flagBytes := make([]byte, flagSize)
	err = binary.Read(r, binary.BigEndian, flagBytes)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.Flag string content unpack error\n" + err.Error())
	}
	this.Flag = string(flagBytes[:len(flagBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.NodeId)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.NodeId unpack error\n" + err.Error())
	}

	var bucketIdSize uint32
	err = binary.Read(r, binary.BigEndian, &bucketIdSize)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.BucketId string size unpack error\n" + err.Error())
	}

	bucketIdBytes := make([]byte, bucketIdSize)
	err = binary.Read(r, binary.BigEndian, bucketIdBytes)
	if err != nil {
		return errors.New("Tb_Bucket_Need_Delete.BucketId string content unpack error\n" + err.Error())
	}
	this.BucketId = string(bucketIdBytes[:len(bucketIdBytes)-1])

	return err
}

const (
	Tb_Object_Slice_Need_DeleteBaseVersion    uint32 = 1
	Tb_Object_Slice_Need_DeleteCurrentVersion uint32 = 1
)

var Tb_Object_Slice_Need_DeleteDBFeilds = &tdrcom.TDRDBFeilds{
	SplittableKey: "ObjectId",
	PrimaryKey:    "ObjectId,SliceId",
	Index2Column: map[string]string{
		"Index_Obj": "ObjectId",
	},
}

// Tb_Object_Slice_Need_Delete
type Tb_Object_Slice_Need_Delete struct {
	NodeId uint64 `tdr_field:"nodeId"`

	BlockPath string `tdr_field:"blockPath"`

	Offset uint64 `tdr_field:"offset"`

	Length uint64 `tdr_field:"length"`

	ObjectId string `tdr_field:"objectId"`

	SliceId uint32 `tdr_field:"sliceId"`

	Type uint32 `tdr_field:"type"`

	Md5 string `tdr_field:"md5"`
}

func NewTb_Object_Slice_Need_Delete() *Tb_Object_Slice_Need_Delete {
	obj := new(Tb_Object_Slice_Need_Delete)
	obj.Init()
	return obj
}

func (this *Tb_Object_Slice_Need_Delete) GetBaseVersion() uint32 {
	return Tb_Object_Slice_Need_DeleteBaseVersion
}

func (this *Tb_Object_Slice_Need_Delete) GetCurrentVersion() uint32 {
	return Tb_Object_Slice_Need_DeleteCurrentVersion
}

func (this *Tb_Object_Slice_Need_Delete) GetTDRDBFeilds() *tdrcom.TDRDBFeilds {
	return Tb_Object_Slice_Need_DeleteDBFeilds
}

func (this *Tb_Object_Slice_Need_Delete) Init() {

}

func (this *Tb_Object_Slice_Need_Delete) Pack(cutVer uint32) ([]byte, error) {
	w := tdrcom.NewWriter()
	if err := this.PackTo(cutVer, w); err != nil {
		return nil, errors.New("Tb_Object_Slice_Need_Delete Pack error\n" + err.Error())
	} else {
		return w.Bytes(), nil
	}
}

func (this *Tb_Object_Slice_Need_Delete) PackTo(cutVer uint32, w *tdrcom.Writer) error {
	// adjust cut version
	if cutVer == 0 || cutVer > Tb_Object_Slice_Need_DeleteCurrentVersion {
		cutVer = Tb_Object_Slice_Need_DeleteCurrentVersion
	}
	// check cut version
	if cutVer < Tb_Object_Slice_Need_DeleteBaseVersion {
		return errors.New("Tb_Object_Slice_Need_Delete cut version must large than Tb_Object_Slice_Need_DeleteBaseVersion\n")
	}

	var err error

	err = binary.Write(w, binary.BigEndian, this.NodeId)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.NodeId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.BlockPath))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.BlockPath string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.BlockPath), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.BlockPath string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Offset)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Offset pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Length)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Length pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.ObjectId))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.ObjectId string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.ObjectId), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.ObjectId string content pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.SliceId)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.SliceId pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, this.Type)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Type pack error\n" + err.Error())
	}

	err = binary.Write(w, binary.BigEndian, uint32(len(this.Md5))+1)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Md5 string size pack error\n" + err.Error())
	}
	err = binary.Write(w, binary.BigEndian, append([]byte(this.Md5), 0))
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Md5 string content pack error\n" + err.Error())
	}

	return nil
}

func (this *Tb_Object_Slice_Need_Delete) Unpack(cutVer uint32, data []byte) error {
	if nil == data {
		return errors.New("Tb_Object_Slice_Need_Delete data is nil")
	}
	return this.UnpackFrom(cutVer, tdrcom.NewReader(data))
}

func (this *Tb_Object_Slice_Need_Delete) UnpackFrom(cutVer uint32, r *tdrcom.Reader) error {
	var err error = nil
	// adjust version
	if cutVer == 0 || cutVer > Tb_Object_Slice_Need_DeleteCurrentVersion {
		cutVer = Tb_Object_Slice_Need_DeleteCurrentVersion
	}
	// check version
	if cutVer < Tb_Object_Slice_Need_DeleteBaseVersion {
		errors.New("Tb_Object_Slice_Need_Delete cut version must large than Tb_Object_Slice_Need_DeleteBaseVersion\n")
	}

	err = binary.Read(r, binary.BigEndian, &this.NodeId)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.NodeId unpack error\n" + err.Error())
	}

	var blockPathSize uint32
	err = binary.Read(r, binary.BigEndian, &blockPathSize)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.BlockPath string size unpack error\n" + err.Error())
	}

	blockPathBytes := make([]byte, blockPathSize)
	err = binary.Read(r, binary.BigEndian, blockPathBytes)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.BlockPath string content unpack error\n" + err.Error())
	}
	this.BlockPath = string(blockPathBytes[:len(blockPathBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.Offset)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Offset unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Length)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Length unpack error\n" + err.Error())
	}

	var objectIdSize uint32
	err = binary.Read(r, binary.BigEndian, &objectIdSize)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.ObjectId string size unpack error\n" + err.Error())
	}

	objectIdBytes := make([]byte, objectIdSize)
	err = binary.Read(r, binary.BigEndian, objectIdBytes)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.ObjectId string content unpack error\n" + err.Error())
	}
	this.ObjectId = string(objectIdBytes[:len(objectIdBytes)-1])

	err = binary.Read(r, binary.BigEndian, &this.SliceId)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.SliceId unpack error\n" + err.Error())
	}

	err = binary.Read(r, binary.BigEndian, &this.Type)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Type unpack error\n" + err.Error())
	}

	var md5Size uint32
	err = binary.Read(r, binary.BigEndian, &md5Size)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Md5 string size unpack error\n" + err.Error())
	}

	md5Bytes := make([]byte, md5Size)
	err = binary.Read(r, binary.BigEndian, md5Bytes)
	if err != nil {
		return errors.New("Tb_Object_Slice_Need_Delete.Md5 string content unpack error\n" + err.Error())
	}
	this.Md5 = string(md5Bytes[:len(md5Bytes)-1])

	return err
}
